{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Team](intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of this task is to develop a machine learning model capable of accurately predicting the author of a text based solely on the presence or absence of specific words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A structured dataset is provided in which each row represents a text sample, and the columns indicate either the presence of specific words in the text or the author of that text.\n",
    "\n",
    "### • Word Columns\n",
    "These columns represent individual words. Each entry is a binary value, where 1 indicates that the word appears in the text, and 0 indicates that it does not.\n",
    "\n",
    "### • author Column\n",
    "This column contains the name of the author who wrote the text. It serves as the target variable that the model must predict.\n",
    "\n",
    "### • Example Structure of the Dataset\n",
    "\n",
    "| word_1 | word_2 | ... | word_n | author        |\n",
    "|:------:|:------:|:---:|:------:|:--------------|\n",
    "|   0    |   1    | ... |   1    | Mason Reed    |\n",
    "|   1    |   1    | ... |   1    | Ava Thompson  |\n",
    "|   0    |   1    | ... |   0    | Liam Carter   |\n",
    "\n",
    "\n",
    "The test dataset follows the same structure as the training dataset, except that it does not include the author column. It contains 2765 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lung</th>\n",
       "      <th>council</th>\n",
       "      <th>solution</th>\n",
       "      <th>quite</th>\n",
       "      <th>rain</th>\n",
       "      <th>hair</th>\n",
       "      <th>skill</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>add</th>\n",
       "      <th>pull</th>\n",
       "      <th>...</th>\n",
       "      <th>stocking</th>\n",
       "      <th>near</th>\n",
       "      <th>oil</th>\n",
       "      <th>dive</th>\n",
       "      <th>many</th>\n",
       "      <th>run</th>\n",
       "      <th>tender</th>\n",
       "      <th>asleep</th>\n",
       "      <th>eat</th>\n",
       "      <th>sweep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lung  council  solution  quite  rain  hair  skill  difficulty  add  pull  \\\n",
       "0     0        0         0      0     0     0      0           0    0     0   \n",
       "1     0        0         0      0     0     0      0           0    0     0   \n",
       "2     0        0         0      0     0     0      0           0    0     0   \n",
       "3     0        0         0      0     0     0      0           0    0     0   \n",
       "4     0        0         0      0     0     0      0           0    0     0   \n",
       "5     0        0         0      0     0     0      0           0    0     0   \n",
       "6     0        0         0      0     0     0      0           0    0     0   \n",
       "7     0        0         0      0     0     0      0           0    0     0   \n",
       "8     0        0         0      0     1     0      0           0    0     0   \n",
       "9     0        0         0      0     0     0      0           0    0     0   \n",
       "\n",
       "   ...  stocking  near  oil  dive  many  run  tender  asleep  eat  sweep  \n",
       "0  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "1  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "2  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "3  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "4  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "5  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "6  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "7  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "8  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "9  ...         0     0    0     0     0    0       0       0    0      0  \n",
       "\n",
       "[10 rows x 380 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'..\\data\\train.csv')\n",
    "test_df = pd.read_csv(r'..\\data\\test.csv')\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.drop(columns='author')\n",
    "y = train_df['author']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "x_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3822 - loss: 1.4628 - val_accuracy: 0.6375 - val_loss: 1.1442\n",
      "Epoch 2/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6307 - loss: 1.0299 - val_accuracy: 0.7844 - val_loss: 0.6946\n",
      "Epoch 3/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.7706 - val_accuracy: 0.7984 - val_loss: 0.5754\n",
      "Epoch 4/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.6657 - val_accuracy: 0.8031 - val_loss: 0.5494\n",
      "Epoch 5/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7876 - loss: 0.5925 - val_accuracy: 0.8219 - val_loss: 0.5392\n",
      "Epoch 6/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.5569 - val_accuracy: 0.8188 - val_loss: 0.5188\n",
      "Epoch 7/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.5099 - val_accuracy: 0.8250 - val_loss: 0.5203\n",
      "Epoch 8/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.4716 - val_accuracy: 0.8234 - val_loss: 0.5332\n",
      "Epoch 9/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.4615 - val_accuracy: 0.8156 - val_loss: 0.5303\n",
      "Epoch 10/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.4163 - val_accuracy: 0.8188 - val_loss: 0.5501\n",
      "Epoch 11/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.3897 - val_accuracy: 0.8234 - val_loss: 0.5401\n",
      "Epoch 12/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3812 - val_accuracy: 0.8188 - val_loss: 0.5350\n",
      "Epoch 13/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8760 - loss: 0.3588 - val_accuracy: 0.8172 - val_loss: 0.5491\n",
      "Epoch 14/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3361 - val_accuracy: 0.8297 - val_loss: 0.5532\n",
      "Epoch 15/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3276 - val_accuracy: 0.8234 - val_loss: 0.5848\n",
      "Epoch 16/100\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.3126 - val_accuracy: 0.8250 - val_loss: 0.5703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x248cd9962c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- Scaling ---\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "# --- Model Architecture ---\n",
    "model = Sequential([\n",
    "    Input(shape=(x_train.shape[1],)),  \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# --- Compile ---\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- Early Stopping ---\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric of the Competition\n",
    "\n",
    "Submissions are evaluated using the F1 Score, with macro averaging applied.\n",
    "The F1 score considers both precision and recall, making it a balanced metric for multi-class classification.\n",
    "\n",
    "The final score is calculated using the formula:\n",
    "\n",
    "$$\n",
    "\\text{score} = \\text{round}(\\text{f1score},\\, 3) \\times 100\n",
    "$$\n",
    "\n",
    "\n",
    "A model’s F1 score is rounded to three decimal places, multiplied by 100, and used as your final score.\n",
    "The maximum possible score is 100, and the minimum acceptable score is 40.\n",
    "If your model achieves an F1 score below 0.40, the final score will be 0.\n",
    "\n",
    "It is recommended that you evaluate your model on the training or validation set using this metric to ensure reliable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "F1 Score (macro): 0.817\n",
      "Final Score: 81.69999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "val_preds = model.predict(x_val)\n",
    "val_pred_labels = val_preds.argmax(axis=1)\n",
    "\n",
    "f1 = f1_score(y_val, val_pred_labels, average='macro')\n",
    "print(\"F1 Score (macro):\", round(f1, 3))\n",
    "print(\"Final Score:\", round(f1, 3) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Test Data and Output\n",
    "\n",
    "Save your model's predictions on the test data in a dataframe.\n",
    "This dataframe must contain a single column named author, where the i-th row is your prediction for the i-th row of the test dataset.\n",
    "\n",
    "|Column|Description|\n",
    "|------|---|\n",
    "|author|Predicted author of the text|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q3Jx3gIdwvts"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "y_test_pred_probs = model.predict(x_test)\n",
    "y_test_pred_labels = y_test_pred_probs.argmax(axis=1)\n",
    "\n",
    "y_test_pred_names = label_encoder.inverse_transform(y_test_pred_labels)\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'author': y_test_pred_names\n",
    "})\n",
    "\n",
    "submission_df.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Team](outro.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
